

<!---
Paper Format
 
Titile [\[paper\]](link)<br />
  *author et al., year*
-->


## Interpretation and Explanationï¼ŒBasic Concepts
- Methods for interpreting and understanding deep neural network [\[paper\]](https://arxiv.org/pdf/1802.00121) <br/> 
  *Gregoire Montavon et al.,2017*

## Disentangling Representations of Neural Networks
###  Computer Vision
- Interpretable Basis Decomposition for Visual Explanation  [\[paper\]](http://people.csail.mit.edu/bzhou/publication/eccv18-IBD)<br />
  *Bolei Zhou et al., 2018*


###  Natural Language Processing


## Building Interpretable Models Based on Abstract Representations
###  Computer Vision
- Interpreting CNNs via Decision Trees [\[paper\]](https://arxiv.org/pdf/1802.00121)<br />
  *Quanshi Zhang et al., 2019*
- Interpreting CNN Knowledge via An Explanatory Graph [\[paper\]](https://arxiv.org/pdf/1708.01785)<br />
  *Quanshi Zhang et al., 2018*


###  Natural Language Processing 
- Extracting Automata from Recurrent Neural Networks Using Queries and Counterexamples [\[paper\]](https://arxiv.org/pdf/1711.09576)<br />
  *Gail Weiss et al., 2017*







## Other Resources
- [https://github.com/Kangyeol-Kim/Awesome-XAI](https://github.com/Kangyeol-Kim/Awesome-XAI)
- [https://github.com/lopusz/awesome-interpretable-machine-learning](https://github.com/lopusz/awesome-interpretable-machine-learning)
- [https://github.com/jphall663/awesome-machine-learning-interpretability](https://github.com/jphall663/awesome-machine-learning-interpretability)
